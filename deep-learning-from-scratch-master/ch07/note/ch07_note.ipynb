{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 畳み込みニューラルネットワーク（CNN）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概要\n",
    "* 畳み込み層とプーリング層をもつニューラルネットワーク(Convolutioanl Nural Network)のこと\n",
    "* 画像分類問題に良く用いられる\n",
    "* CNNでは入出力データを **特徴マップ**、入力（出力)データを特に **入力（出力）特徴マップ** という "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込み層\n",
    "* 入力データの形状を維持したまま（例えば1チャンネル×28ピクセル×28ピクセルの3次元データのまま）学習を行う\n",
    "* 今までの全結合層（Affine層）では1次配列に成形して学習を行っていた\n",
    "* その場合空間情報（例えば近いピクセル同士は色が近い、端のピクセルは画像分類に影響しない）が失われるため、その解決策として畳み込み層が考案された"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込み演算\n",
    "\n",
    "* 入力データ上を **フィルター** (カーネルとも)のウィンドウをスライドさせて出力を計算する\n",
    "* フィルターの要素と入力データの要素の乗算し、その和を出力値とする（これを**積和計算**ということにする）\n",
    "* フィルターのパラメータが全結合層の「重み」に対応する\n",
    "* 畳み込み層のバイアスは出力値に一律同じ値を加算する\n",
    "* 出力サイズは $$入力サイズ - フィルターサイズ + 1 = 出力サイズ$$\n",
    "* 畳み込み計算を繰り返すと出力サイズがどんどん小さくなる。そこで入力データの周囲に固定値を詰めることで次元を維持する。これを **パディング** という\n",
    "* パディングした場合の次元は $$入力サイズ - フィルターサイズ + パディング幅 × 2 + 1 = 出力サイズ$$\n",
    "* フィルターをスライドさせる間隔を **ストライド** という（入力サイズが大きいときに次元縮約のするため？？）\n",
    "* ストライドした場合のサイズは $$\\frac{入力サイズ - フィルターサイズ + パディング幅 × 2}{ストライド間隔}  + 1 = 出力サイズ$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プーリング層\n",
    "\n",
    "* 縦・横方向の空間を小さくする演算（層）\n",
    "* 特徴の位置ずれを吸収するために用いられる。\n",
    "    * 例えば人の顔を認識するとき、個人によって目や口の位置が違うため、⓵顔のパーツを認識する⓶位置ずれを吸収して同一視する（だいたいパーツの場所があっていれば人の顔とみなす）という2段階の認識が必要\n",
    "* プーリング種類と目的（引用： https://stanford.edu/~shervine/l/ja/teaching/cs-230/cheatsheet-convolutional-neural-networks ）\n",
    "    * MAXプーリング：ビュー範囲の中で最大値を選ぶ。検出した特徴を保持するために使用する。一般的に使用される手法（なのでゼロつくではこちらを使用する）。\n",
    "    * AVERAGEプーリング：ビュー範囲の平均値を選ぶ。特徴マップをダウンサイズするために使用する。LeNetに使用される（らしいがこれが何かわからん）\n",
    "* 一般にストライド幅はフィルターサイズと同じに設定する（"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNは脳の働きを模したモデル\n",
    "\n",
    "引用：[畳み込みネットワークの「基礎の基礎」を理解する　～ディープラーニング入門｜第2回](https://www.imagazine.co.jp/%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E3%80%8C%E5%9F%BA%E7%A4%8E%E3%81%AE%E5%9F%BA%E7%A4%8E%E3%80%8D%E3%82%92%E7%90%86%E8%A7%A3%E3%81%99/#:~:text=%E2%97%86-,%E3%83%97%E3%83%BC%E3%83%AA%E3%83%B3%E3%82%B0%E5%B1%A4,%E3%81%AE%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%AD%E3%83%B3%E3%81%A8%E7%B5%90%E5%90%88%E3%81%99%E3%82%8B%E3%80%82)\n",
    "\n",
    "　単純型細胞は、ある特定の形状に反応する細胞である。さまざまな形状に反応する単純型細胞があり、それらが連携して活動することで複雑な形状の物体を認識する。\n",
    "\n",
    "　一方の複雑型細胞は、形状の空間的なずれを吸収するような働きをする。単純型細胞だけだと、ある形状の位置がずれると別の形状と見なすが、複雑型細胞は空間的な位置ずれを吸収し、同一形状と見なせるように働く（図表1）。 \n",
    "\n",
    "　畳み込みネットワークはこの2つの細胞の働きを模倣するように考案されており、単純型細胞に対応する「畳み込み層」、複雑型細胞に対応する「プーリング層」というコンポーネントが用意されている。　\n",
    "\n",
    "\n",
    "⇒\n",
    "CNNでは\n",
    "1. 畳み込み層により特定の形状を認識（単純型細胞の役割）\n",
    "2. プーリング層により入力画像の位置ずれを吸収（=おおよそ場所があっていればニューロンが発火するようにする）\n",
    "\n",
    "という2層で人の脳の動きを再現している。なので必ずこの順番になる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## im2colの説明\n",
    "\n",
    "![](im2col1.jpg)\n",
    "\n",
    "![](im2col2.jpg)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
