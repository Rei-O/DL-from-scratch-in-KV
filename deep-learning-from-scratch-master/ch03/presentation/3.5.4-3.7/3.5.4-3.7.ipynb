{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 出力層のニューロンの数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![出力層ニューロン](fig/出力ニューロンの数.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 手書き数字認識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考URL\n",
    "https://qiita.com/python_walker/items/e4d2ae5b7196cb07402b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1 MNISTデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request # URLを扱うためのモジュール\n",
    "\n",
    "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
    "\n",
    "key_file = {\n",
    "    'train_img':'train-images-idx3-ubyte.gz',\n",
    "    'train_label':'train-labels-idx1-ubyte.gz',\n",
    "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
    "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
    "}\n",
    "\n",
    "import os\n",
    "working_directory=os.getcwd() # Pythonが実行されている作業ディレクトリの取得(get current working directory)\n",
    "dataset_dir = working_directory  # 作業ディレクトリを下記でダウンロードするデータセットの格納先パスとして保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for v in key_file.values():\n",
    "#     print(f'Data→{v}')\n",
    "#     file_path = dataset_dir + '/' + v\n",
    "#     urllib.request.urlretrieve(url_base + v, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_img  : train-images-idx3-ubyte.gz\n",
      "train_label  : train-labels-idx1-ubyte.gz\n",
      "test_img  : t10k-images-idx3-ubyte.gz\n",
      "test_label  : t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "for k in key_file.keys():\n",
    "    v=key_file[k]\n",
    "    print(f'{k}  : {v}')\n",
    "    file_path = dataset_dir + '/' + v #ダウンロードするファイルのデータセット\n",
    "    urllib.request.urlretrieve(url_base + v, file_path) # Web上のファイルのダウンロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "◆ MNISTデータの仕様<br>\n",
    "https://weblabo.oscasierra.net/python/ai-mnist-data-detail.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■画像データ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>　画像データが保存されたファイル(train-images-idx3-ubyte / t10k-images-idx3-ubyte)は、次のような仕様になっています。</p>\n",
    "<table>\n",
    "<thead><tr>\n",
    "<th style=\"text-align:left\">offset</th>\n",
    "<th style=\"text-align:left\">type</th>\n",
    "<th style=\"text-align:left\">value</th>\n",
    "<th style=\"text-align:left\">description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">0000</td>\n",
    "<td style=\"text-align:left\">32 bit integer</td>\n",
    "<td style=\"text-align:left\">0x00000803(2051)</td>\n",
    "<td style=\"text-align:left\">識別子(定数)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">0004</td>\n",
    "<td style=\"text-align:left\">32 bit integer</td>\n",
    "<td style=\"text-align:left\">60000</td>\n",
    "<td style=\"text-align:left\">画像データの数</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">0008</td>\n",
    "<td style=\"text-align:left\">32 bit integer</td>\n",
    "<td style=\"text-align:left\">28</td>\n",
    "<td style=\"text-align:left\">1画像あたりのデータ行数</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">0012</td>\n",
    "<td style=\"text-align:left\">32 bit integer</td>\n",
    "<td style=\"text-align:left\">28</td>\n",
    "<td style=\"text-align:left\">1画像あたりのデータ列数</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">0016</td>\n",
    "<td style=\"text-align:left\">unsigned byte</td>\n",
    "<td style=\"text-align:left\">0 ～ 255</td>\n",
    "<td style=\"text-align:left\">1つめの画像の1ピクセル目の値</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">0017</td>\n",
    "<td style=\"text-align:left\">unsigned byte</td>\n",
    "<td style=\"text-align:left\">0 ～ 255</td>\n",
    "<td style=\"text-align:left\">1つめの画像の2ピクセル目の値</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">....</td>\n",
    "<td style=\"text-align:left\">....</td>\n",
    "<td style=\"text-align:left\">....</td>\n",
    "<td style=\"text-align:left\">....</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">xxxx</td>\n",
    "<td style=\"text-align:left\">unsigned byte</td>\n",
    "<td style=\"text-align:left\">0 ～ 255</td>\n",
    "<td style=\"text-align:left\">最後の画像の784ピクセル目の値</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<p>ピクセルの値は、0 から 255 までの値で、0 が白を, 255 が黒を表します。</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8ビットカラー 【8-bit color】 256色 (2の8乗)<br>\n",
    "![8ビットカラー](fig/8ビットカラー.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://atmarkit.itmedia.co.jp/ait/articles/2001/22/news012.html <br>\n",
    "![手書き数字外観](fig/手書き数字画像データ外観.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "想定されるtrain個数(28×28×60000) : 47040000\n",
      "\n",
      "実際の個数 : 47040016　⇦ 想定よりも16個数が多い。恐らくヘッダーの情報をはじめの16つに含んでいるため?\n",
      "\n",
      "offset:16を設定 : 47040000　\n",
      "\n",
      "中身 : [0 0 0 ... 0 0 0]\n",
      "\n",
      "中身の最大値 : 255\n",
      "\n",
      "中身の最小値 : 0\n",
      "\n",
      "型   : uint8\n",
      "\n",
      "次元 : 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#試しにtrain_imgを見てみる\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "file_path = dataset_dir +  '/' + key_file['train_img']\n",
    "\n",
    "with gzip.open(file_path, 'rb') as f: #バイナリモードで読み込み\n",
    "    data_no_offset = np.frombuffer(f.read(), np.uint8) # https://stackoverflow.com/questions/22236749/numpy-what-is-the-difference-between-frombuffer-and-fromstring\n",
    "    \n",
    "\n",
    "with gzip.open(file_path, 'rb') as f: #バイナリモードで読み込み\n",
    "    data = np.frombuffer(f.read(), np.uint8, offset=16) # https://stackoverflow.com/questions/22236749/numpy-what-is-the-difference-between-frombuffer-and-fromstring\n",
    "\n",
    "\n",
    "print(f'想定されるtrain個数(28×28×60000) : {(28**2)*60000}\\n')\n",
    "print(f'実際の個数 : {len(data_no_offset)}　⇦ 想定よりも16個数が多い。恐らくヘッダーの情報をはじめの16つに含んでいるため?\\n')\n",
    "print(f'offset:16を設定 : {len(data)}　\\n')\n",
    "print(f'中身 : {data}\\n')\n",
    "print(f'中身の最大値 : {np.max(data_no_offset)}\\n')\n",
    "print(f'中身の最小値 : {np.min(data_no_offset)}\\n')\n",
    "print(f'型   : {data.dtype}\\n')\n",
    "print(f'次元 : {len(data.shape)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1, 100, 255,   0,   1, 255, 254], dtype=uint8)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtypeにunit8を使った時の挙動確認\n",
    "np_sample = np.array([0,1,100,255,256,257,-1,-2], dtype='uint8')\n",
    "np_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データの予測はニューラルネットがよしなにやってくれる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■ラベルデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ラベルデータが保存されたファイル(train-labels-idx1-ubyte / t10k-labels-idx1-ubyte)は、次のような仕様になっています。</p>\n",
    "<table>\n",
    "<thead><tr>\n",
    "<th style=\"text-align:left\">offset</th>\n",
    "<th style=\"text-align:left\">type</th>\n",
    "<th style=\"text-align:left\">value</th>\n",
    "<th style=\"text-align:left\">description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">0000</td>\n",
    "<td style=\"text-align:left\">32 bit integer</td>\n",
    "<td style=\"text-align:left\">0x00000801(2049)</td>\n",
    "<td style=\"text-align:left\">識別子(定数)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">0004</td>\n",
    "<td style=\"text-align:left\">32 bit integer</td>\n",
    "<td style=\"text-align:left\">60000 or 10000</td>\n",
    "<td style=\"text-align:left\">ラベルデータの数</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">0008</td>\n",
    "<td style=\"text-align:left\">unsigned byte</td>\n",
    "<td style=\"text-align:left\">0 ～ 9</td>\n",
    "<td style=\"text-align:left\">1つ目のデータのラベル</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">0009</td>\n",
    "<td style=\"text-align:left\">unsigned byte</td>\n",
    "<td style=\"text-align:left\">0 ～ 9</td>\n",
    "<td style=\"text-align:left\">2つ目のデータのラベル</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">....</td>\n",
    "<td style=\"text-align:left\">....</td>\n",
    "<td style=\"text-align:left\">....</td>\n",
    "<td style=\"text-align:left\">....</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:left\">xxxx</td>\n",
    "<td style=\"text-align:left\">unsigned byte</td>\n",
    "<td style=\"text-align:left\">0 ～ 9</td>\n",
    "<td style=\"text-align:left\">最後のデータのラベル</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(file_name):\n",
    "    file_path = dataset_dir + '/' + file_name\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1, 784)\n",
    "\n",
    "    return data\n",
    "\n",
    "def load_label(file_name):\n",
    "    file_path = dataset_dir + '/' + file_name\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "\n",
    "    return labels\n",
    "\n",
    "dataset = {}\n",
    "dataset['train_img'] = load_img(key_file['train_img'])\n",
    "dataset['train_label'] = load_label(key_file['train_label'])\n",
    "dataset['test_img'] = load_img(key_file['test_img'])\n",
    "dataset['test_label'] = load_label(key_file['test_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_img次元  : (60000, 784)\n",
      "\n",
      "train_label次元  : (60000,)\n",
      "\n",
      "test_img次元  : (10000, 784)\n",
      "\n",
      "test_label次元  : (10000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'train_img次元  : {dataset[\"train_img\"].shape}\\n')\n",
    "print(f'train_label次元  : {dataset[\"train_label\"].shape}\\n')\n",
    "print(f'test_img次元  : {dataset[\"test_img\"].shape}\\n')\n",
    "print(f'test_label次元  : {dataset[\"test_label\"].shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pikle形式で保管\n",
    "import pickle\n",
    "\n",
    "save_file = dataset_dir + '/mnist.pkl'    #拡張子は.pkl\n",
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(dataset, f, -1)    #-1は最も高いプロトコルバージョンで保存することを指定している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したデータの読み込み\n",
    "with open(save_file, 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_img': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'train_label': array([5, 0, 4, ..., 5, 6, 8], dtype=uint8),\n",
       " 'test_img': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'test_label': array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset[train_img] : (60000, 784)\n",
      "\n",
      "dataset[train_label] : (60000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'dataset[train_img] : {dataset[\"train_img\"].shape}\\n')\n",
    "print(f'dataset[train_label] : {dataset[\"train_label\"].shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■画像データ\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■正解データ(ラベル)\n",
      "\n",
      "8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# train画像データ順番\n",
    "i=59999\n",
    "example = dataset['train_img'][i].reshape((28, 28))\n",
    "\n",
    "print(f'■画像データ\\n')\n",
    "plt.imshow(example)\n",
    "plt.show()\n",
    "\n",
    "print(f'■正解データ(ラベル)\\n')\n",
    "print(f'{dataset[\"train_label\"][i]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 ニューラルネットワークの推論処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    x = x - np.max(x, axis=-1, keepdims=True)   # オーバーフロー対策\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _change_one_hot_label(X):\n",
    "    T = np.zeros((X.size, 10))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "    return T\n",
    "\n",
    "\n",
    "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
    "    \"\"\"MNISTデータセットの読み込み\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    normalize : 画像のピクセル値を0.0~1.0に正規化する\n",
    "    one_hot_label :\n",
    "        one_hot_labelがTrueの場合、ラベルはone-hot配列として返す\n",
    "        one-hot配列とは、たとえば[0,0,1,0,0,0,0,0,0,0]のような配列\n",
    "    flatten : 画像を一次元配列に平にするかどうか\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (訓練画像, 訓練ラベル), (テスト画像, テストラベル)\n",
    "    \"\"\"\n",
    "#     if not os.path.exists(save_file):\n",
    "#         init_mnist()\n",
    "\n",
    "    with open(save_file, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    if normalize:\n",
    "        for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].astype(np.float32)\n",
    "            dataset[key] /= 255.0\n",
    "\n",
    "    if one_hot_label:\n",
    "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
    "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])\n",
    "\n",
    "    if not flatten:\n",
    "         for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
    "\n",
    "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "# sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import pickle\n",
    "# from dataset.mnist import load_mnist\n",
    "# from common.functions import sigmoid, softmax\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "#     (x_train, t_train), (x_test, t_test) = (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label'])\n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networkの設定概要(sample_weight.pkl)\n",
      "\n",
      "W1 : (784, 50)\n",
      "\n",
      "b1 : (50,)\n",
      "\n",
      "W2 : (50, 100)\n",
      "\n",
      "b2 : (100,)\n",
      "\n",
      "W3 : (100, 10)\n",
      "\n",
      "b3 : (10,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = init_network()\n",
    "\n",
    "print(f'networkの設定概要(sample_weight.pkl)\\n')\n",
    "print(f'W1 : {network[\"W1\"].shape}\\n')\n",
    "print(f'b1 : {network[\"b1\"].shape}\\n')\n",
    "print(f'W2 : {network[\"W2\"].shape}\\n')\n",
    "print(f'b2 : {network[\"b2\"].shape}\\n')\n",
    "print(f'W3 : {network[\"W3\"].shape}\\n')\n",
    "print(f'b3 : {network[\"b3\"].shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネットワークは、入力層を784 個、出力層を10 個のニュー\n",
    "ロンで構成します。入力層の784 という数字は、画像サイズの28 × 28 = 784 から、\n",
    "また、出力層の10 という数字は、10 クラス分類（数字の0 から9 の10 クラス）ら来ています。また、隠れ層が2 つあり、ひとつ目の隠れ層が50 個、2 つ目の層が\n",
    "100 個のニューロンを持つものとします。この50 と100 という数字は、任意の値に\n",
    "設定できます。それでは初めに、3 つの関数―― get_data()、init_network()、\n",
    "predict()――を定義します（ここで示すコードはch03/neuralnet_mnist.py に\n",
    "あります）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ニューロン](fig/図.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (10000, 784)\n",
      "\n",
      "t : (10000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "\n",
    "print(f'x : {np.shape(x)}\\n')\n",
    "print(f't : {np.shape(t)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p= np.argmax(y) # 最も確率の高い要素のインデックスを取得\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3 バッチ処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,_=get_data()\n",
    "network = init_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1,W2,W3=network['W1'], network['W2'], network['W3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape : (10000, 784)\n",
      "\n",
      "x[0].shape : (784,)\n",
      "\n",
      "W1.shape : (784, 50)\n",
      "\n",
      "W2.shape : (50, 100)\n",
      "\n",
      "W3.shape : (100, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'x.shape : {x.shape}\\n')\n",
    "print(f'x[0].shape : {x[0].shape}\\n')\n",
    "print(f'W1.shape : {W1.shape}\\n')\n",
    "print(f'W2.shape : {W2.shape}\\n')\n",
    "print(f'W3.shape : {W3.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![バッチ](fig/バッチ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 10000 # バッチの数\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習時には、バッチごとに平均を取ったりすることもあるので要確認\n",
    "# data loaderのデフォルト値は64になっている\n",
    "# 64, 128などはメモリの切りが良くて早くなる?(2の階乗ごとがメモリにとって良い)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch.shape : (10000, 784)\n",
      "\n",
      "x_batch :\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "y_batch.shape :\n",
      " (10000, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 抜粋\n",
    "j=0\n",
    "x_batch= x[j:j+batch_size]\n",
    "y_batch = predict(network, x_batch)\n",
    "print(f'x_batch.shape : {x_batch.shape}\\n')\n",
    "print(f'x_batch :\\n {x_batch}\\n')\n",
    "print(f'y_batch.shape :\\n {y_batch.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章では、ニューラルネットワークの順方向の伝播（forward propagation）につ\n",
    "いて解説しました。本章で説明したニューラルネットワークは、前章のパーセプト\n",
    "ロンと、ニューロンの信号が階層的に伝わるという点で同じでした。しかし、次の\n",
    "ニューロンへ信号を送信する際に、信号を変化させる活性化関数に大きな違いがあり\n",
    "ました。ニューラルネットワークでは活性化関数が滑らかに変化するシグモイド関\n",
    "数、パーセプトロンでは信号が急に変化するステップ関数を使用しました。この違い\n",
    "がニューラルネットワークの学習において重要になってきますが、これは次章で説明\n",
    "します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "signate_titanic_Kokichi_sample.ipynb のコピー",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
