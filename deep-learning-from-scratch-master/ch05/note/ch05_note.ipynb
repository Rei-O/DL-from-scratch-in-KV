{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数と活性化関数\n",
    "\n",
    "誤差逆伝播法では「出力層から逆伝播する値=予測値-正解値（誤差）」になるような損失関数と出力層の活性化関数の組み合わせを選ぶ必要がある。\n",
    "\n",
    "以下がその代表的な組み合わせである。\n",
    "| 問題種別 | 活性化関数         | 損失関数             | \n",
    "| -------- | ------------------ | -------------------- | \n",
    "| 分類問題 | ソフトマックス関数 | 交差エントロピー関数 | \n",
    "| 回帰問題 | 恒等関数           | 二乗和誤差関数       | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワークの1枚絵\n",
    "\n",
    "これまで学習した内容を1枚の絵にまとめると以下のようになる:\n",
    "\n",
    "![](ニューラルネットワーク図解-1.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算グラフ\n",
    "\n",
    "* 計算グラフは微分の連鎖律を追いやすくなる\n",
    "* 以下を組み合わせることで誤差逆伝播を実装することができる\n",
    "\n",
    "![](【ゼロつく】5章計算グラフ-1.jpg)<br>\n",
    "![](【ゼロつく】5章計算グラフ-2.jpg)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 式5.13の導出\n",
    "\n",
    "![](【ゼロつく】式5.13導出-1.jpg)\n",
    "\n",
    "![](【ゼロつく】式5.13導出-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 誤差逆伝播の過程を導出\n",
    "\n",
    "![](【ヨビノリ】誤差逆伝播法の解説-1.jpg)\n",
    "\n",
    "![](【ヨビノリ】誤差逆伝播法の解説-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
